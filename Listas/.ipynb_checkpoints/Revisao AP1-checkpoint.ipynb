{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.datasets import load_boston, load_breast_cancer\n",
    "from sklearn import preprocessing, linear_model, svm, metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##     Use K-Fold Cross Validation com k = 5 para resolver os seguintes problemas de machine learning: \n",
    "        Regressão \n",
    "            Dataset: boston house-prices dataset\n",
    "            Aplicar Standardization nas features.\n",
    "            Comparar os resultados dos seguintes algoritmos: Gradient Descent, Linear Regression, kNN, SVM.\n",
    "            Usar as seguintes métricas: RMSE, MAE.\n",
    "            Escolher a melhor técnica e criar um modelo final usando todo o dataset para treinar o modelo.\n",
    "        Classificação \n",
    "            Dataset: breast cancer wisconsin dataset\n",
    "            Aplicar Normalization nas features.\n",
    "            Comparar os resultados dos seguintes algoritmos: Logistic Regression, kNN, Naive Bayes, SVM.\n",
    "            Mostrar a matriz de confusão.\n",
    "            Usar as seguintes métricas: Accuracy, Precision, Recall, F1-Measure, AUC (Area Under the Curve).\n",
    "            Plotar curva ROC dos diferentes algoritmos.\n",
    "            Escolher a melhor técnica e criar um modelo final usando todo o dataset para treinar o modelo.\n",
    "        Você pode usar as implementações do Scikit Learn.\n",
    "        Preencha seus resultados de RMSE (para o problema de regressão) e Accuracy (para o problema de classificação) na seguinte planilha online. \n",
    "            Nossa primeira competiçãozinha interna!!!\n",
    "            Tentem melhorar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boston, y_boston = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "set_kfold.get_n_splits()\n",
    "\n",
    "for train_index, test_index in set_kfold.split(X_boston,y_boston):\n",
    "    X_train, X_test = X_boston[train_index], X_boston[test_index]\n",
    "    y_train, y_test = y_boston[train_index], y_boston[test_index]\n",
    "    \n",
    "    #Standardize - StandardScaler\n",
    "    std = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train_std = std.transform(X_train)\n",
    "    X_test_std = std.transform(X_test)\n",
    "    \n",
    "    #Gradient Descent - SGDRegressor\n",
    "    model_gdr = linear_model.SGDRegressor().fit(X_train_std, y_train)\n",
    "    y_pred_gdr = model_gdr.predict(X_test_std)\n",
    "    \n",
    "    rmse_gdr = np.sqrt(metrics.mean_squared_error(y_test, y_pred_gdr))\n",
    "    mae_gdr = metrics.mean_absolute_error(y_test, y_pred_gdr)\n",
    "    \n",
    "    #Linear Regression - LinearRegression\n",
    "    model_lr = linear_model.LinearRegression().fit(X_train_std, y_train)\n",
    "    y_pred_lr = model_lr.predict(X_test_std)\n",
    "    \n",
    "    rmse_lr = np.sqrt(metrics.mean_squared_error(y_test, y_pred_gdr))\n",
    "    mae_lr = metrics.mean_absolute_error(y_test, y_pred_gdr)\n",
    "    \n",
    "    #kNN - KNeighborsRegressor\n",
    "    model_knnr = KNeighborsRegressor().fit(X_train_std, y_train)\n",
    "    y_pred_knnr = model_knnr.predict(X_test_std)\n",
    "    \n",
    "    rmse_knnr = np.sqrt(metrics.mean_squared_error(y_test, y_pred_gdr))\n",
    "    mae_knnr = metrics.mean_absolute_error(y_test, y_pred_gdr)\n",
    "    \n",
    "    #Support Vector Machine - \n",
    "    model_svr = svm.SVR().fit(X_train_std, y_train)\n",
    "    y_pred_svr = model_svr.predict(X_test_std)\n",
    "    \n",
    "    rmse_svr = np.sqrt(metrics.mean_squared_error(y_test, y_pred_gdr))\n",
    "    mae_svr = metrics.mean_absolute_error(y_test, y_pred_gdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer, y_cancer = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold_cancer = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "skfold_cancer.get_n_splits()\n",
    "\n",
    "for train_index, test_index in skfold_cancer.split(X_cancer, y_cancer):\n",
    "    Xc_train, Xc_test = X_cancer[train_index], X_cancer[test_index]\n",
    "    yc_train, yc_test = y_cancer[train_index], y_cancer[test_index]\n",
    "    \n",
    "    #Normalization - MinMaxScaler\n",
    "    nm = preprocessing.MinMaxScaler().fit(Xc_train)\n",
    "    X_train_nm = nm.transform(Xc_train)\n",
    "    X_test_nm = nm.transform(Xc_test)\n",
    "    \n",
    "    #Logistic Regression - LogisticRegression\n",
    "    model_lrr = linear_model.LogisticRegression().fit(X_train_nm, yc_train)\n",
    "    y_pred_lrr = model_lrr.predict(X_test_nm)\n",
    "    \n",
    "    acc_lrr = metrics.accuracy_score(yc_test, y_pred_lrr)\n",
    "    \n",
    "    #kNN - \n",
    "    model_knnr = KNeighborsClassifier().fit(X_train_nm, yc_train)\n",
    "    y_pred_knnr = model_knnr.predict(X_test_nm)\n",
    "    \n",
    "    #Naive Bayes - \n",
    "    model_nb = GaussianNB().fit(X_train_nm, yc_train)\n",
    "    y_pred_nb = model_nb.predict(X_test_nm)\n",
    "    \n",
    "    #SVC - \n",
    "    model_svc = svm.SVC().fit(X_train_nm, yc_train)\n",
    "    y_pred_svc = model_svc.predict(X_test_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
