{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.datasets import load_boston, load_breast_cancer\n",
    "from sklearn import preprocessing, linear_model, svm, metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão \n",
    "\n",
    "    Dataset: boston house-prices dataset\n",
    "    Aplicar Standardization nas features.\n",
    "    Comparar os resultados dos seguintes algoritmos: Gradient Descent, Linear Regression, kNN, Naive Bayes,  SVM\n",
    "    Usar as seguintes métricas: RMSE, MAE\n",
    "    Escolher a melhor técnica e criar um modelo final usando todo o dataset para treinar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "treino.get_n_splits(X, y)\n",
    "\n",
    "vetor_rmse_dtr = []\n",
    "vetor_mae_dtr  = []\n",
    "\n",
    "vetor_rmse_dtr1 = []\n",
    "vetor_mae_dtr1  = []\n",
    "\n",
    "vetor_rmse_dtr2 = []\n",
    "vetor_mae_dtr2  = []\n",
    "\n",
    "#----------------------------\n",
    "\n",
    "vetor_rmse_rfr = []\n",
    "vetor_mae_rfr  = []\n",
    "\n",
    "vetor_rmse_rfr1 = []\n",
    "vetor_mae_rfr1  = []\n",
    "\n",
    "vetor_rmse_rfr2 = []\n",
    "vetor_mae_rfr2  = []\n",
    "\n",
    "vetor_rmse_rfr3 = []\n",
    "vetor_mae_rfr3  = []\n",
    "\n",
    "vetor_rmse_rfr4 = []\n",
    "vetor_mae_rfr4  = []\n",
    "\n",
    "vetor_rmse_rfr5 = []\n",
    "vetor_mae_rfr5  = []\n",
    "\n",
    "vetor_rmse_rfr6 = []\n",
    "vetor_mae_rfr6  = []\n",
    "\n",
    "vetor_rmse_rfr7 = []\n",
    "vetor_mae_rfr7  = []\n",
    "\n",
    "vetor_rmse_rfr8 = []\n",
    "vetor_mae_rfr8  = []\n",
    "\n",
    "vetor_rmse_gbr = []\n",
    "vetor_mae_gbr  = []\n",
    "\n",
    "vetor_rmse_gbr1 = []\n",
    "vetor_mae_gbr1  = []\n",
    "\n",
    "vetor_rmse_gbr2 = []\n",
    "vetor_mae_gbr2  = []\n",
    "\n",
    "\n",
    "for train_index, test_index in treino.split(X,y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    #standardize\n",
    "    std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train_std = std_scale.transform(X_train)\n",
    "    X_test_std = std_scale.transform(X_test)\n",
    "    \n",
    "    \n",
    "    #Random Forest Regressor\n",
    "    model_rfr = RandomForestRegressor(random_state=42, n_estimators=50, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_rfr = model_rfr.predict(X_test_std)\n",
    "    vetor_rmse_rfr.append(sqrt(mean_squared_error(y_test, y_pred_rfr)))\n",
    "    vetor_mae_rfr.append(mean_absolute_error(y_test, y_pred_rfr))\n",
    "    \n",
    "    model_rfr1 = RandomForestRegressor(random_state=42, n_estimators=50, max_depth=5).fit(X_train_std, y_train)\n",
    "    y_pred_rfr1 = model_rfr1.predict(X_test_std)\n",
    "    vetor_rmse_rfr1.append(sqrt(mean_squared_error(y_test, y_pred_rfr1)))\n",
    "    vetor_mae_rfr1.append(mean_absolute_error(y_test, y_pred_rfr1))\n",
    "    \n",
    "    model_rfr2 = RandomForestRegressor(random_state=42, n_estimators=50, max_depth=7).fit(X_train_std, y_train)\n",
    "    y_pred_rfr2 = model_rfr2.predict(X_test_std)\n",
    "    vetor_rmse_rfr2.append(sqrt(mean_squared_error(y_test, y_pred_rfr2)))\n",
    "    vetor_mae_rfr2.append(mean_absolute_error(y_test, y_pred_rfr2))\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------------#\n",
    "    \n",
    "    model_rfr3 = RandomForestRegressor(random_state=42, n_estimators=50, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_rfr3 = model_rfr3.predict(X_test_std)\n",
    "    vetor_rmse_rfr3.append(sqrt(mean_squared_error(y_test, y_pred_rfr3)))\n",
    "    vetor_mae_rfr3.append(mean_absolute_error(y_test, y_pred_rfr3))\n",
    "    \n",
    "    model_rfr4 = RandomForestRegressor(random_state=42, n_estimators=50, max_depth=5).fit(X_train_std, y_train)\n",
    "    y_pred_rfr4 = model_rfr4.predict(X_test_std)\n",
    "    vetor_rmse_rfr4.append(sqrt(mean_squared_error(y_test, y_pred_rfr4)))\n",
    "    vetor_mae_rfr4.append(mean_absolute_error(y_test, y_pred_rfr4))\n",
    "    \n",
    "    model_rfr5 = RandomForestRegressor(random_state=42, n_estimators=50, max_depth=7).fit(X_train_std, y_train)\n",
    "    y_pred_rfr5 = model_rfr5.predict(X_test_std)\n",
    "    vetor_rmse_rfr5.append(sqrt(mean_squared_error(y_test, y_pred_rfr5)))\n",
    "    vetor_mae_rfr5.append(mean_absolute_error(y_test, y_pred_rfr5))\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    \n",
    "    model_rfr6 = RandomForestRegressor(random_state=42, n_estimators=200, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_rfr6 = model_rfr6.predict(X_test_std)\n",
    "    vetor_rmse_rfr6.append(sqrt(mean_squared_error(y_test, y_pred_rfr6)))\n",
    "    vetor_mae_rfr6.append(mean_absolute_error(y_test, y_pred_rfr6))\n",
    "    \n",
    "    model_rfr7 = RandomForestRegressor(random_state=42, n_estimators=200, max_depth=5).fit(X_train_std, y_train)\n",
    "    y_pred_rfr7 = model_rfr7.predict(X_test_std)\n",
    "    vetor_rmse_rfr7.append(sqrt(mean_squared_error(y_test, y_pred_rfr7)))\n",
    "    vetor_mae_rfr7.append(mean_absolute_error(y_test, y_pred_rfr7))\n",
    "    \n",
    "    model_rfr8 = RandomForestRegressor(random_state=42, n_estimators=200, max_depth=7).fit(X_train_std, y_train)\n",
    "    y_pred_rfr8 = model_rfr8.predict(X_test_std)\n",
    "    vetor_rmse_rfr8.append(sqrt(mean_squared_error(y_test, y_pred_rfr8)))\n",
    "    vetor_mae_rfr8.append(mean_absolute_error(y_test, y_pred_rfr8))\n",
    "    \n",
    "    \n",
    "    #Decision Tree Regressor\n",
    "    \n",
    "    model_dtr = DecisionTreeRegressor(random_state=42, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_dtr = model_dtr.predict(X_test_std)\n",
    "    vetor_rmse_dtr.append(sqrt(mean_squared_error(y_test, y_pred_dtr)))\n",
    "    vetor_mae_dtr.append(mean_absolute_error(y_test, y_pred_dtr))\n",
    "    \n",
    "    model_dtr1 = DecisionTreeRegressor(random_state=42, max_depth=5).fit(X_train_std, y_train)\n",
    "    y_pred_dtr1 = model_dtr1.predict(X_test_std)\n",
    "    vetor_rmse_dtr1.append(sqrt(mean_squared_error(y_test, y_pred_dtr1)))\n",
    "    vetor_mae_dtr1.append(mean_absolute_error(y_test, y_pred_dtr1))\n",
    "    \n",
    "    model_dtr2 = DecisionTreeRegressor(random_state=42, max_depth=7).fit(X_train_std, y_train)\n",
    "    y_pred_dtr2 = model_dtr2.predict(X_test_std)\n",
    "    vetor_rmse_dtr2.append(sqrt(mean_squared_error(y_test, y_pred_dtr2)))\n",
    "    vetor_mae_dtr2.append(mean_absolute_error(y_test, y_pred_dtr2))\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------------#\n",
    " \n",
    "    \n",
    "    #Gradient Boosting Regressor\n",
    "    model_gbr = GradientBoostingRegressor(random_state=42, n_estimators=50, learning_rate=0.1, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_gbr = model_gtr.predict(X_test_std)\n",
    "    vetor_rmse_gbr.append(sqrt(mean_squared_error(y_test, y_pred_gbr)))\n",
    "    vetor_mae_gbr.append(mean_absolute_error(y_test, y_pred_gbr))\n",
    "    \n",
    "    model_gbr1 = GradientBoostingRegressor(random_state=42, n_estimators=50, learning_rate=0.05, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_gbr1 = model_gbr1.predict(X_test_std)\n",
    "    vetor_rmse_gbr1.append(sqrt(mean_squared_error(y_test, y_pred_gbr1)))\n",
    "    vetor_mae_gbr1.append(mean_absolute_error(y_test, y_pred_gbr1))\n",
    "    \n",
    "    model_gbr2 = GradientBoostingRegressor(random_state=42, n_estimators=50, learning_rate=0.01, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_gbr2 = model_gbr2.predict(X_test_std)\n",
    "    vetor_rmse_gbr2.append(sqrt(mean_squared_error(y_test, y_pred_gbr2)))\n",
    "    vetor_mae_gbr2.append(mean_absolute_error(y_test, y_pred_gbr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFR : RMSE = 3.9541780941009876 / MAE = 2.8422887595791555\n",
      "RFR1: RMSE = 3.4227800844926364 / MAE = 2.408471347431258\n",
      "RFR2: RMSE = 3.3158325507332704 / MAE = 2.2825839298954804\n",
      "RFR3: RMSE = 3.9541780941009876 / MAE = 2.8422887595791555\n",
      "RFR4: RMSE = 3.4227800844926364 / MAE = 2.408471347431258\n",
      "RFR5: RMSE = 3.3158325507332704 / MAE = 2.2825839298954804\n",
      "RFR6: RMSE = 3.878170968827985 / MAE = 2.8041997007376067\n",
      "RFR7: RMSE = 3.403391992478904 / MAE = 2.3883888271579705\n",
      "RFR8: RMSE = 3.310783183924305 / MAE = 2.2738728553720158\n",
      "DTR : RMSE = 4.789308380224346 / MAE = 3.3879143241970526\n",
      "DTR1: RMSE = 3.9758723362144637 / MAE = 2.721497143112603\n",
      "DTR2: RMSE = 4.364830545006392 / MAE = 2.8582696777947953\n",
      "GBR : RMSE = 2.3278566080550407 / MAE = 1.670336410159043\n",
      "GBR1: RMSE = 3.4107121756040497 / MAE = 2.496696842797329\n",
      "GBR2: RMSE = 6.425429412248441 / MAE = 4.745890588618422\n"
     ]
    }
   ],
   "source": [
    "class_names = ['RFR ', 'RFR1', 'RFR2', 'RFR3', 'RFR4', 'RFR5', 'RFR6', 'RFR7', 'RFR8', 'DTR ', 'DTR1', 'DTR2', 'GBR ', 'GBR1', 'GBR2']\n",
    "class_ = [vetor_rmse_rfr, vetor_rmse_rfr1, vetor_rmse_rfr2, vetor_rmse_rfr3, vetor_rmse_rfr4, vetor_rmse_rfr5, vetor_rmse_rfr6, vetor_rmse_rfr7, vetor_rmse_rfr8,\n",
    "         vetor_rmse_dtr, vetor_rmse_dtr1, vetor_rmse_dtr2, \n",
    "         vetor_rmse_gbr, vetor_rmse_gbr1, vetor_rmse_gbr2]\n",
    "class_1 = [vetor_mae_rfr, vetor_mae_rfr1, vetor_mae_rfr2, vetor_mae_rfr3, vetor_mae_rfr4, vetor_mae_rfr5, vetor_mae_rfr6, vetor_mae_rfr7, vetor_mae_rfr8, \n",
    "           vetor_mae_dtr, vetor_mae_dtr1, vetor_mae_dtr2, \n",
    "          vetor_mae_gbr, vetor_mae_gbr1, vetor_mae_gbr2]\n",
    "for i in range(0,len(class_names)):\n",
    "    print(class_names[i] + ': RMSE = ' + str(np.mean(class_[i])) + ' / MAE = ' + str(np.mean(class_1[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escolher a melhor técnica e criar um modelo final usando todo o dataset para treinar o modelo. (gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Final = 1.8792408767426567\n"
     ]
    }
   ],
   "source": [
    "final_scale = preprocessing.StandardScaler().fit(X, y)\n",
    "X_std_final = final_scale.transform(X)\n",
    "\n",
    "model_regressao_final = GradientBoostingRegressor(random_state=42, learning_rate=0.1, n_estimators=50, max_depth=3)\n",
    "model_regressao_final.fit(X_std_final, y)\n",
    "y_pred_final = model_regressao_final.predict(X_std_final)\n",
    "rmse_final = sqrt(metrics.mean_squared_error(y, y_pred_final))\n",
    "print(\"RMSE Final = {}\".format(rmse_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação \n",
    "\n",
    "    Dataset: breast cancer wisconsin dataset\n",
    "    Aplicar Normalization nas features.\n",
    "    Comparar os resultados dos seguintes algoritmos: Logistic Regression, kNN, Naive Bayes, SVM\n",
    "    Mostrar a matriz de confusão\n",
    "    Usar as seguintes métricas: Accuracy, Precision, Recall, F1-Measure, AOC\n",
    "    Plotar curva ROC dos diferentes algoritmos.\n",
    "    Escolher a melhor técnica e criar um modelo final usando todo o dataset para treinar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc, yc = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "treinoc = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "treinoc.get_n_splits(Xc, yc)\n",
    "\n",
    "vetor_acc_dtc = []\n",
    "vetor_pre_dtc  = []\n",
    "vetor_rec_dtc  = []\n",
    "vetor_f1_dtc  = []\n",
    "\n",
    "vetor_acc_dtc1 = []\n",
    "vetor_pre_dtc1  = []\n",
    "vetor_rec_dtc1  = []\n",
    "vetor_f1_dtc1  = []\n",
    "\n",
    "vetor_acc_dtc2 = []\n",
    "vetor_pre_dtc2  = []\n",
    "vetor_rec_dtc2  = []\n",
    "vetor_f1_dtc2 = []\n",
    "\n",
    "#----------------------------\n",
    "\n",
    "vetor_acc_rfc = []\n",
    "vetor_pre_rfc  = []\n",
    "vetor_rec_rfc  = []\n",
    "vetor_f1_rfc  = []\n",
    "\n",
    "vetor_acc_rfc1 = []\n",
    "vetor_pre_rfc1  = []\n",
    "vetor_rec_rfc1  = []\n",
    "vetor_f1_rfc1  = []\n",
    "\n",
    "vetor_acc_rfc2 = []\n",
    "vetor_pre_rfc2  = []\n",
    "vetor_rec_rfc2  = []\n",
    "vetor_f1_rfc2  = []\n",
    "\n",
    "vetor_acc_rfc3 = []\n",
    "vetor_pre_rfc3 = []\n",
    "vetor_rec_rfc3  = []\n",
    "vetor_f1_rfc3 = []\n",
    "\n",
    "vetor_acc_rfc4 = []\n",
    "vetor_pre_rfc4  = []\n",
    "vetor_rec_rfc4  = []\n",
    "vetor_f1_rfc4 = []\n",
    "\n",
    "vetor_acc_rfc5 = []\n",
    "vetor_pre_rfc5  = []\n",
    "vetor_rec_rfc5  = []\n",
    "vetor_f1_rfc5  = []\n",
    "\n",
    "vetor_acc_rfc6 = []\n",
    "vetor_pre_rfc6  = []\n",
    "vetor_rec_rfc6  = []\n",
    "vetor_f1_rfc6  = []\n",
    "\n",
    "vetor_acc_rfc7 = []\n",
    "vetor_pre_rfc7  = []\n",
    "vetor_rec_rfc7  = []\n",
    "vetor_f1_rfc7  = []\n",
    "\n",
    "vetor_acc_rfc8 = []\n",
    "vetor_pre_rfc8  = []\n",
    "vetor_rec_rfc8  = []\n",
    "vetor_f1_rfc8  = []\n",
    "\n",
    "#------------------------------------------------------------------------------------------#\n",
    "\n",
    "vetor_acc_gbc = []\n",
    "vetor_pre_gbc  = []\n",
    "vetor_rec_gbc  = []\n",
    "vetor_f1_gbc  = []\n",
    "\n",
    "vetor_acc_gbc1 = []\n",
    "vetor_pre_gbc1  = []\n",
    "vetor_rec_gbc1  = []\n",
    "vetor_f1_gbc1  = []\n",
    "\n",
    "\n",
    "vetor_acc_gbc2 = []\n",
    "vetor_pre_gbc2  = []\n",
    "vetor_rec_gbc2  = []\n",
    "vetor_f1_gbc2  = []\n",
    "\n",
    "for train_index, test_index in treino.split(Xc,yc):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = Xc[train_index], Xc[test_index]\n",
    "    y_train, y_test = yc[train_index], yc[test_index]\n",
    "    \n",
    "    #Normalization\n",
    "    std_scale = preprocessing.MinMaxScaler().fit(X_train)\n",
    "    X_train_std = std_scale.transform(X_train)\n",
    "    X_test_std = std_scale.transform(X_test)\n",
    "    \n",
    "    #Random Forest Classifier\n",
    "    model_rfc = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_rfc = model_rfc.predict(X_test_std)\n",
    "    vetor_acc_rfc.append(metrics.accuracy_score(y_test, y_pred_rfc))\n",
    "    vetor_pre_rfc.append(metrics.precision_score(y_test, y_pred_rfc))\n",
    "    vetor_rec_rfc.append(metrics.recall_score(y_test, y_pred_rfc))\n",
    "    vetor_f1_rfc.append(metrics.f1_score(y_test, y_pred_rfc))\n",
    "    \n",
    "    model_rfc1 = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=5).fit(X_train_std, y_train)\n",
    "    y_pred_rfc1 = model_rfc1.predict(X_test_std)\n",
    "    vetor_acc_rfc1.append(metrics.accuracy_score(y_test, y_pred_rfc1))\n",
    "    vetor_pre_rfc1.append(metrics.precision_score(y_test, y_pred_rfc1))\n",
    "    vetor_rec_rfc1.append(metrics.recall_score(y_test, y_pred_rfc1))\n",
    "    vetor_f1_rfc1.append(metrics.f1_score(y_test, y_pred_rfc1))\n",
    "    \n",
    "    model_rfc2 = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=7).fit(X_train_std, y_train)\n",
    "    y_pred_rfc2 = model_rfc2.predict(X_test_std)\n",
    "    vetor_acc_rfc2.append(metrics.accuracy_score(y_test, y_pred_rfc2))\n",
    "    vetor_pre_rfc2.append(metrics.precision_score(y_test, y_pred_rfc2))\n",
    "    vetor_rec_rfc2.append(metrics.recall_score(y_test, y_pred_rfc2))\n",
    "    vetor_f1_rfc2.append(metrics.f1_score(y_test, y_pred_rfc2))    \n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------------#\n",
    "    \n",
    "    model_rfc3 = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_rfc3 = model_rfc3.predict(X_test_std)\n",
    "    vetor_acc_rfc3.append(metrics.accuracy_score(y_test, y_pred_rfc3))\n",
    "    vetor_pre_rfc3.append(metrics.precision_score(y_test, y_pred_rfc3))\n",
    "    vetor_rec_rfc3.append(metrics.recall_score(y_test, y_pred_rfc3))\n",
    "    vetor_f1_rfc3.append(metrics.f1_score(y_test, y_pred_rfc3))\n",
    "\n",
    "    model_rfc4 = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=5).fit(X_train_std, y_train)\n",
    "    y_pred_rfc4 = model_rfc4.predict(X_test_std)\n",
    "    vetor_acc_rfc4.append(metrics.accuracy_score(y_test, y_pred_rfc4))\n",
    "    vetor_pre_rfc4.append(metrics.precision_score(y_test, y_pred_rfc4))\n",
    "    vetor_rec_rfc4.append(metrics.recall_score(y_test, y_pred_rfc4))\n",
    "    vetor_f1_rfc4.append(metrics.f1_score(y_test, y_pred_rfc4))\n",
    "\n",
    "    model_rfc5 = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=7).fit(X_train_std, y_train)\n",
    "    y_pred_rfc5 = model_rfc5.predict(X_test_std)\n",
    "    vetor_acc_rfc5.append(metrics.accuracy_score(y_test, y_pred_rfc5))\n",
    "    vetor_pre_rfc5.append(metrics.precision_score(y_test, y_pred_rfc5))\n",
    "    vetor_rec_rfc5.append(metrics.recall_score(y_test, y_pred_rfc5))\n",
    "    vetor_f1_rfc5.append(metrics.f1_score(y_test, y_pred_rfc5))\n",
    "   \n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    \n",
    "    model_rfc6 = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=7).fit(X_train_std, y_train)\n",
    "    y_pred_rfc6 = model_rfc6.predict(X_test_std)\n",
    "    vetor_acc_rfc6.append(metrics.accuracy_score(y_test, y_pred_rfc6))\n",
    "    vetor_pre_rfc6.append(metrics.precision_score(y_test, y_pred_rfc6))\n",
    "    vetor_rec_rfc6.append(metrics.recall_score(y_test, y_pred_rfc6))\n",
    "    vetor_f1_rfc6.append(metrics.f1_score(y_test, y_pred_rfc6))\n",
    "    \n",
    "    model_rfc7 = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=7).fit(X_train_std, y_train)\n",
    "    y_pred_rfc7 = model_rfc7.predict(X_test_std)\n",
    "    vetor_acc_rfc7.append(metrics.accuracy_score(y_test, y_pred_rfc7))\n",
    "    vetor_pre_rfc7.append(metrics.precision_score(y_test, y_pred_rfc7))\n",
    "    vetor_rec_rfc7.append(metrics.recall_score(y_test, y_pred_rfc7))\n",
    "    vetor_f1_rfc7.append(metrics.f1_score(y_test, y_pred_rfc7))\n",
    "    \n",
    "    model_rfc8 = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=7).fit(X_train_std, y_train)\n",
    "    y_pred_rfc8 = model_rfc8.predict(X_test_std)\n",
    "    vetor_acc_rfc8.append(metrics.accuracy_score(y_test, y_pred_rfc8))\n",
    "    vetor_pre_rfc8.append(metrics.precision_score(y_test, y_pred_rfc8))\n",
    "    vetor_rec_rfc8.append(metrics.recall_score(y_test, y_pred_rfc8))\n",
    "    vetor_f1_rfc8.append(metrics.f1_score(y_test, y_pred_rfc8))\n",
    "    \n",
    "    \n",
    "    #Decision Tree Classifier\n",
    "    \n",
    "    model_dtc = DecisionTreeClassifier(random_state=42, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_dtc = model_dtc.predict(X_test_std)\n",
    "    vetor_acc_dtc.append(metrics.accuracy_score(y_test, y_pred_dtc))\n",
    "    vetor_pre_dtc.append(metrics.precision_score(y_test, y_pred_dtc))\n",
    "    vetor_rec_dtc.append(metrics.recall_score(y_test, y_pred_dtc))\n",
    "    vetor_f1_dtc.append(metrics.f1_score(y_test, y_pred_dtc))\n",
    "    \n",
    "    model_dtc1 = DecisionTreeClassifier(random_state=42, max_depth=5).fit(X_train_std, y_train)\n",
    "    y_pred_dtc1 = model_dtc1.predict(X_test_std)\n",
    "    vetor_acc_dtc1.append(metrics.accuracy_score(y_test, y_pred_dtc1))\n",
    "    vetor_pre_dtc1.append(metrics.precision_score(y_test, y_pred_dtc1))\n",
    "    vetor_rec_dtc1.append(metrics.recall_score(y_test, y_pred_dtc1))\n",
    "    vetor_f1_dtc1.append(metrics.f1_score(y_test, y_pred_dtc1))\n",
    "    \n",
    "    model_dtc2 = DecisionTreeClassifier(random_state=42, max_depth=7).fit(X_train_std, y_train)\n",
    "    y_pred_dtc2 = model_dtc2.predict(X_test_std)\n",
    "    vetor_acc_dtc2.append(metrics.accuracy_score(y_test, y_pred_dtc2))\n",
    "    vetor_pre_dtc2.append(metrics.precision_score(y_test, y_pred_dtc2))\n",
    "    vetor_rec_dtc2.append(metrics.recall_score(y_test, y_pred_dtc2))\n",
    "    vetor_f1_dtc2.append(metrics.f1_score(y_test, y_pred_dtc2))\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------------#\n",
    " \n",
    "    \n",
    "    #Gradient Boosting Regressor\n",
    "    model_gbc = GradientBoostingClassifier(random_state=42, n_estimators=50, learning_rate=0.1, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_gbc = model_gbc.predict(X_test_std)\n",
    "    vetor_acc_gbc.append(metrics.accuracy_score(y_test, y_pred_gbc))\n",
    "    vetor_pre_gbc.append(metrics.precision_score(y_test, y_pred_gbc))\n",
    "    vetor_rec_gbc.append(metrics.recall_score(y_test, y_pred_gbc))\n",
    "    vetor_f1_gbc.append(metrics.f1_score(y_test, y_pred_gbc))\n",
    "    \n",
    "    \n",
    "    model_gbc1 = GradientBoostingClassifier(random_state=42, n_estimators=50, learning_rate=0.05, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_gbc1 = model_gbc1.predict(X_test_std)\n",
    "    vetor_acc_gbc1.append(metrics.accuracy_score(y_test, y_pred_gbc1))\n",
    "    vetor_pre_gbc1.append(metrics.precision_score(y_test, y_pred_gbc1))\n",
    "    vetor_rec_gbc1.append(metrics.recall_score(y_test, y_pred_gbc1))\n",
    "    vetor_f1_gbc1.append(metrics.f1_score(y_test, y_pred_gbc1))\n",
    "    \n",
    "    model_gbc2 = GradientBoostingClassifier(random_state=42, n_estimators=50, learning_rate=0.05, max_depth=3).fit(X_train_std, y_train)\n",
    "    y_pred_gbc2 = model_gbc2.predict(X_test_std)\n",
    "    vetor_acc_gbc2.append(metrics.accuracy_score(y_test, y_pred_gbc2))\n",
    "    vetor_pre_gbc2.append(metrics.precision_score(y_test, y_pred_gbc2))\n",
    "    vetor_rec_gbc2.append(metrics.recall_score(y_test, y_pred_gbc2))\n",
    "    vetor_f1_gbc2.append(metrics.f1_score(y_test, y_pred_gbc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC : Acc = 0.9490296537804689 / Prec = 0.9505086657202788 / Rec = 0.9689485624738936 / F1 = 0.9595922254566188\n",
      "RFC1: Acc = 0.9560627231796305 / Prec = 0.9608895353013001 / Rec = 0.9688972368812605 / F1 = 0.9648462094858801\n",
      "RFC2: Acc = 0.9578326346840551 / Prec = 0.9637665474621995 / Rec = 0.9692849089107234 / F1 = 0.9664253393665158\n",
      "RFC3: Acc = 0.9490296537804689 / Prec = 0.9505086657202788 / Rec = 0.9689485624738936 / F1 = 0.9595922254566188\n",
      "RFC4: Acc = 0.9560627231796305 / Prec = 0.9608895353013001 / Rec = 0.9688972368812605 / F1 = 0.9648462094858801\n",
      "RFC5: Acc = 0.9578326346840551 / Prec = 0.9637665474621995 / Rec = 0.9692849089107234 / F1 = 0.9664253393665158\n",
      "RFC6: Acc = 0.9578326346840551 / Prec = 0.9637665474621995 / Rec = 0.9692849089107234 / F1 = 0.9664253393665158\n",
      "RFC7: Acc = 0.9578326346840551 / Prec = 0.9637665474621995 / Rec = 0.9692849089107234 / F1 = 0.9664253393665158\n",
      "RFC8: Acc = 0.9578326346840551 / Prec = 0.9637665474621995 / Rec = 0.9692849089107234 / F1 = 0.9664253393665158\n",
      "DTC : Acc = 0.934979040521658 / Prec = 0.9279143847636998 / Rec = 0.972050484726541 / F1 = 0.9490886909405679\n",
      "DTC1: Acc = 0.9420121099208197 / Prec = 0.9475493482573485 / Rec = 0.9608855302780045 / F1 = 0.9541316929619038\n",
      "DTC2: Acc = 0.9332246545567457 / Prec = 0.9491795693949795 / Rec = 0.9440354474199335 / F1 = 0.9465112726598186\n",
      "GBC : Acc = 0.9578326346840553 / Prec = 0.9588203047897637 / Rec = 0.9746992129165768 / F1 = 0.9666300046775641\n",
      "GBC1: Acc = 0.9560627231796305 / Prec = 0.9557481641988683 / Rec = 0.9608855302780045 / F1 = 0.9650403722100368\n",
      "GBC2: Acc = 0.9560627231796305 / Prec = 0.9557481641988683 / Rec = 0.9440354474199335 / F1 = 0.9650403722100368\n"
     ]
    }
   ],
   "source": [
    "class_names2 = ['RFC ', 'RFC1', 'RFC2', 'RFC3', 'RFC4', 'RFC5', 'RFC6', 'RFC7', 'RFC8', 'DTC ', 'DTC1', 'DTC2', 'GBC ', 'GBC1', 'GBC2']\n",
    "class2_  = [vetor_acc_rfc, vetor_acc_rfc1, vetor_acc_rfc2, vetor_acc_rfc3, vetor_acc_rfc4, vetor_acc_rfc5, vetor_acc_rfc6, vetor_acc_rfc7, vetor_acc_rfc8,\n",
    "            vetor_acc_dtc, vetor_acc_dtc1, vetor_acc_dtc2, vetor_acc_gbc, vetor_acc_gbc1, vetor_acc_gbc2]\n",
    "class2_1 = [vetor_pre_rfc, vetor_pre_rfc1, vetor_pre_rfc2, vetor_pre_rfc3, vetor_pre_rfc4, vetor_pre_rfc5, vetor_pre_rfc6, vetor_pre_rfc7, vetor_pre_rfc8,\n",
    "            vetor_pre_dtc, vetor_pre_dtc1, vetor_pre_dtc2, vetor_pre_gbc, vetor_pre_gbc1, vetor_pre_gbc2]\n",
    "class2_2 = [vetor_rec_rfc, vetor_rec_rfc1, vetor_rec_rfc2, vetor_rec_rfc3, vetor_rec_rfc4, vetor_rec_rfc5, vetor_rec_rfc6, vetor_rec_rfc7, vetor_rec_rfc8,\n",
    "           vetor_rec_dtc, vetor_rec_dtc1, vetor_rec_dtc2, vetor_rec_gbc, vetor_rec_dtc1, vetor_rec_dtc2]\n",
    "class2_3 = [vetor_f1_rfc, vetor_f1_rfc1, vetor_f1_rfc2, vetor_f1_rfc3, vetor_f1_rfc4, vetor_f1_rfc5, vetor_f1_rfc6, vetor_f1_rfc7, vetor_f1_rfc8,\n",
    "           vetor_f1_dtc, vetor_f1_dtc1, vetor_f1_dtc2, vetor_f1_gbc, vetor_f1_gbc1, vetor_f1_gbc2]\n",
    "for i in range(0,len(class_names)):\n",
    "    print(class_names2[i] + ': Acc = ' + str(np.mean(class2_[i])) \n",
    "                          + ' / Prec = ' + str(np.mean(class2_1[i])) \n",
    "                          + ' / Rec = ' + str(np.mean(class2_2[i])) \n",
    "                          + ' / F1 = ' + str(np.mean(class2_3[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolher a melhor técnica e criar um modelo final usando todo o dataset para treinar o modelo. (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "model_classificacao_final = GradientBoostingClassifier(random_state=42, n_estimators=50, learning_rate=0.1, max_depth=3)\n",
    "model_classificacao_final.fit(Xc, yc)\n",
    "y_classificacao_final = model_classificacao_final.predict(Xc)\n",
    "print('Accuracy = {}'.format(metrics.accuracy_score(yc, y_classificacao_final)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
