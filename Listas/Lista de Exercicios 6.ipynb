{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold as sk, KFold\n",
    "from sklearn import metrics as m, neighbors as n\n",
    "import numpy as np\n",
    "import knn as k, dist_metrics as dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agora avalie e compare sua implementação de KNNClassifier usando a distância euclidiana e a distância manhattan. Compare seus resultados com a implementação do scikit learn somente para a distância euclidiana. \n",
    "\n",
    "    Use o dataset winequality-white.csv em sua avaliação. Este dataset pode ser usado para classificação ou regressão. Nesta questão vamos usá-lo para classificação, onde a última coluna é classe.\n",
    "    Use o Stratified KFold Cross-Validation do Scikit Learn com k=3. Há um exemplo semelhante de uso neste jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = np.genfromtxt(\"datasets/winequality-white.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados[:, :11]\n",
    "y = dados[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    3 ... 4895 4896 4897] TEST: [   2   21   22 ... 4886 4889 4893]\n",
      "TRAIN: [   1    2    4 ... 4892 4893 4897] TEST: [   0    3    5 ... 4894 4895 4896]\n",
      "TRAIN: [   0    2    3 ... 4894 4895 4896] TEST: [   1    4    8 ... 4888 4892 4897]\n"
     ]
    }
   ],
   "source": [
    "train = sk(n_splits=3, shuffle=True, random_state=42)\n",
    "train.get_n_splits(X, y)\n",
    "\n",
    "for train_index, test_index in train.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distância euclidiana vs Distância manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of my KNNClassifier with euclidean: 0.39594843462246776\n"
     ]
    }
   ],
   "source": [
    "model_1 = k.KNNClassifier(3, 'euclidean')\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "y_pred_1 = [model_1.predict(X_test[i]) for i in range(len(X_test))]\n",
    "\n",
    "#print(y_pred)\n",
    "\n",
    "print(\"Accuracy of my KNNClassifier with euclidean: {}\".format(m.accuracy_score(y_test, y_pred_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of my KNNClassifier with manhattan: 0.41497851442602823\n"
     ]
    }
   ],
   "source": [
    "model_2 = k.KNNClassifier(3, 'manhattan')\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_2 = [model_2.predict(X_test[i]) for i in range(len(X_test))]\n",
    "\n",
    "#print(y_pred_1)\n",
    "\n",
    "print(\"Accuracy of my KNNClassifier with manhattan: {}\".format(m.accuracy_score(y_test, y_pred_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit learn vs distância euclidiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Sklearn's KNNClassifier with euclidean: 0.47882136279926335\n"
     ]
    }
   ],
   "source": [
    "#scikit learn\n",
    "model_SK = n.KNeighborsClassifier(3, metric='euclidean')\n",
    "model_SK.fit(X_train, y_train)\n",
    "\n",
    "y_pred_SK = [model_SK.predict(np.array([X_test[i]])) for i in range(len(X_test))]\n",
    "\n",
    "print(\"Accuracy of Sklearn's KNNClassifier with euclidean: {}\".format(m.accuracy_score(y_test, y_pred_SK)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Agora avalie e compare sua implementação de KNNRegressor usando a distância euclidiana e a distância manhattan. Compare seus resultados com a implementação do scikit learn somente para a distância euclidiana.\n",
    "\n",
    "Use o dataset pima-indians-diabetes.csv em sua avaliação.\n",
    "\n",
    "Use o KFold Cross-Validation do Scikit Learn com k=5 (http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html). Há um exemplo semelhante de uso neste jupyter notebook (https://github.com/regispires/aulas-machine-learning/blob/master/11-Stratified%20Split.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatando a entrada...\n"
     ]
    }
   ],
   "source": [
    "train_ = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_.get_n_splits(X, y)\n",
    "\n",
    "for train_index_, test_index_ in train_.split(X, y):\n",
    "    #print(\"TRAIN:\", train_index_, \"TEST:\", test_index_)\n",
    "    X_train_, X_test_ = X[train_index_], X[test_index_]\n",
    "    y_train_, y_test_ = y[train_index_], y[test_index_]\n",
    "    \n",
    "print(\"Formatando a entrada...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of my KNNRegressor with manhattan: 0.7227374872318691\n"
     ]
    }
   ],
   "source": [
    "model_r1 = k.KNNRegressor(5, 'manhattan')\n",
    "model_r1.fit(X_train_, y_train_)\n",
    "\n",
    "y_pred_r1= [model_r1.predict(X_test_[i]) for i in range(len(X_test_))]\n",
    "\n",
    "print(\"MSE of my KNNRegressor with manhattan: {}\".format(m.mean_squared_error(y_test_, y_pred_r1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of my KNNRegressor with euclidean: 0.7493769152196118\n"
     ]
    }
   ],
   "source": [
    "model_r2 = k.KNNRegressor(5, 'euclidean')\n",
    "model_r2.fit(X_train_, y_train_)\n",
    "\n",
    "y_pred_r2 = [model_r2.predict(X_test_[i]) for i in range(len(X_test_))]\n",
    "\n",
    "print(\"MSE of my KNNRegressor with euclidean: {}\".format(m.mean_squared_error(y_test_, y_pred_r2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Sklearn's KNNRegressor with euclidean: 0.678896833503575\n"
     ]
    }
   ],
   "source": [
    "model_RG = n.KNeighborsRegressor(5, metric='euclidean')\n",
    "model_RG.fit(X_train_, y_train_)\n",
    "\n",
    "y_pred_RG = [model_RG.predict(np.array([X_test_[i]])) for i in range(len(X_test_))]\n",
    "\n",
    "\n",
    "print(\"MSE of Sklearn's KNNRegressor with euclidean: {}\".format(m.mean_squared_error(y_test_, y_pred_RG)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
